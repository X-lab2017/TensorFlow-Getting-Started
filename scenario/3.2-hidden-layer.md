# 隐藏层
默认架构仅包含一个输出层,这会影响性能和准确性。 在此步骤中，我们将向网络添加另一个密集层。 整个代码可以在hidden.py文件中看到。

![](http://kfcoding-static.oss-cn-hangzhou.aliyuncs.com/gitcourse-TensorFlow_getting_started/hidden.png)

与一个输出层的情况一样，代码应该从定义占位符开始，占位符表示展平的数字的图像和相应的标签。
```
training_data = tf.placeholder(tf.float32, [None, image_size*image_size])
labels = tf.placeholder(tf.float32, [None, labels_size])
```
然后我们将隐藏层定义为密集层。 我们选择使用1024个神经元和reLU）作为激活函数。 因为它将是另一个密集层，我们需要定义权重和偏差变量。
```
W_h = tf.Variable(tf.truncated_normal([image_size*image_size, hidden_size], stddev=0.1))
b_h = tf.Variable(tf.constant(0.1, shape=[hidden_size]))
```
TensorFlow提供tf.nn.relu函数,它将在执行矩阵乘法后应用。
```
hidden = tf.nn.relu(tf.matmul(training_data, W_h) + b_h)
```
作为画龙点睛，我们将隐藏图层与输出图层连接起来并返回所需的对象。 请注意，我们更改了权重变量的维度以适应隐藏层而不是输入层。
```
W = tf.Variable(tf.truncated_normal([hidden_size, labels_size], stddev=0.1))
b = tf.Variable(tf.constant(0.1, shape=[labels_size]))
```
```
output = tf.matmul(hidden, W) + b
```
您可以使用以下命令运行整个步骤：
```
python hidden.py
```
